# -*- coding: utf-8 -*-
"""ISE2DS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mOdelPMBQapoQrenqM1vR5jgv3ZiryDn

**TEAM MEMBERS**
1.  Saurabh Vijay Bhurse - 21310047
2.  Sajid Rafik Sheikh - 21310055

**Class - TY BTECH Electrical**

**Problem Statement** : Increase sales by identifying the factors that influence customer behavior.

**Datasets Involved:**

*   Sales data
*   Customer data


* **Dataset Used** :https://drive.google.com/file/d/1QpqRZ6wFv46V1SHDuXolh_Jd6yozoICi/view?usp=sharing

**Context:**
This is a sales transaction data set of UK-based e-commerce (online retail) for one year. This London-based shop has been selling gifts and homewares for adults and children through the website since 2007. Their customers come from all over the world and usually make direct purchases for themselves. There are also small businesses that buy in bulk and sell to other customers through retail outlet channels.
The data set contains 10 rows and 7 columns. The following is the description of each column.

1. TransactionNo (Qualitative/Categorical): a six-digit unique number that defines each transaction. The letter “C” in the code indicates a cancellation.
2. Date (Quantitative/Numeric(Discrete)): the date when each transaction was generated.
3.   ProductNo (Qualitative/Categorical): a five or six-digit unique character used to identify a
specific product
4.Product (Qualitative/Categorical): product/item name.
5.Price (Quantitative/Numeric(Continuos)): the price of each product per unit in pound
sterling (£).
6.Quantity (Quantitative/numeric): the quantity of each product per transaction. Negative
values related to cancelled transactions
7.CustomerNo(Qualitative/Categorical) a five-digit unique number that defines each
customer.
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import calendar
from datetime import datetime
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from scipy.sparse import hstack
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
SalesData=pd.read_csv('/content/Sales Transaction v.4a.csv')
print("Shape before data cleaning",SalesData.shape)


SalesData=SalesData.drop_duplicates()
print('Shape After data cleaning:', SalesData.shape)

SalesData.head(10)

SalesData.info()

SalesData.nunique()

SalesData=SalesData.dropna()

SalesData['Date'] = pd.to_datetime(SalesData['Date'], format='%m/%d/%Y')

SalesData['Quantity'] = SalesData['Quantity'].astype(float)
SalesData['Day'] = SalesData['Date'].dt.strftime('%A')
SalesData['Month'] = SalesData['Date'].dt.month
SalesData['DayOfMonth'] = SalesData['Date'].dt.day

SalesData['Sales Total'] = SalesData['Price']*SalesData['Quantity']

# Dropping rows with 2018
data = SalesData.loc[SalesData['Date'].dt.year != 2018].copy()

data

# Create a transactions and cancelation variable
trans = data[data['Sales Total'] >= 0].groupby('Month')['Sales Total'].sum()
cancl = data[data['Sales Total'] <= 0].groupby('Month')['Sales Total'].sum()

# Create a seasonal trend visualization
months = np.arange(1, 13)
width = 0.5

fig = go.Figure()

fig.add_trace(go.Bar(
    x=months - width/2,
    y=trans,
    name='Total Sales',
    marker_color='blue',
    hovertemplate='%{y:.2f} Million'
))

fig.add_trace(go.Bar(
    x=months + width/2,
    y=cancl.abs(),
    name='Canceled Sales',
    marker_color='red',
    hovertemplate='%{y:.2f} Million'
))

fig.update_layout(
    xaxis_title='Month',
    yaxis_title='Total in Millions',
    title='Sales Analysis by Month',
    showlegend=True,
    xaxis=dict(
        tickmode='array',
        tickvals=months,
        ticktext=[calendar.month_name[month] for month in months],
        tickangle=45
    ),
    barmode='group'
)

fig.show()

filtered_data = data[data['Sales Total'] >= 0].copy()

country_sales = filtered_data.groupby('Country')['Sales Total'].sum()

labels = country_sales.index
values = country_sales.values

fig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='none')])

fig.update_layout(title='Total Sales by Country')

fig.show()

sampled_data = data.sample(n=100000)  # Used to improve hovertool lag

fig = px.scatter(sampled_data, x='Price', y='Quantity', title='Price vs Quantity',
                 labels={'Price': 'Price', 'Quantity': 'Quantity'}, render_mode='webgl')

fig.update_layout(xaxis_range=[0, 40], yaxis_range=[0, 500])

fig.update_traces(mode='markers', selector=dict(type='scatter'))

fig.update_traces(showlegend=False)

fig.show()

##Checking for outliers in the data

sns.boxplot(y = 'Quantity', data = SalesData)
plt.show()

# Calculate the IQR(interquartile range)
IQR = np.percentile(SalesData["Quantity"], 75) - np.percentile(SalesData["Quantity"], 25)
print(IQR)

# Calculate the Interquartile Range (IQR)
Q1 = np.percentile(SalesData['Quantity'], 25)
Q3 = np.percentile(SalesData['Quantity'], 75)
IQR = Q3 - Q1
print("IQR is ", IQR)

# Define the upper and lower bounds for identifying outliers
upper_bound = Q3 + 1.5 * IQR
lower_bound = Q1 - 1.5 * IQR

# Filter outliers based on the bounds
outliers = (SalesData['Quantity'] > upper_bound) | (SalesData['Quantity'] < lower_bound)

# Remove the outliers
SalesData = SalesData[~outliers]
SalesData.shape

sns.boxplot(y = 'Quantity', data = SalesData)
plt.show()

SalesData.shape

SalesData.describe()

"""**Machine learning problem**: For this problem the target variable is 'Price' while the input are the 'ProductName' , 'Quantity' , 'Country' :
                              

1.   LinearRegression can be used to predict the sales
                            
2.   Decision Tree Algorithm can also be used

**Implementation using PYTHON**
"""

SalesData_train, SalesData_test = train_test_split(SalesData, test_size =0.2, random_state = 42)
SalesData_train, SalesData_val = train_test_split(SalesData_train, test_size=0.5, random_state=42)

# Define Features and Targets
features = ['ProductName', 'Quantity', 'Country']
target = ['Price']

X_train = SalesData_train[features]
y_train = SalesData_train[target]
X_val = SalesData_val[features]
y_val = SalesData_val[target]
X_test = SalesData_test[features]
y_test = SalesData_test[target]

# Define features and target variables for training, validation, and test data
X_train = SalesData_train[['ProductName', 'Quantity', 'Country']]
y_train = SalesData_train['Price']

X_val = SalesData_val[['ProductName', 'Quantity', 'Country']]
y_val = SalesData_val['Price']

X_test = SalesData_test[['ProductName', 'Quantity', 'Country']]
y_test = SalesData_test['Price']

# Initialize OneHotEncoder for categorical columns
onehot_encoder = OneHotEncoder(sparse=True, handle_unknown='ignore')

# Fit and transform the categorical columns in training data
X_train_encoded = onehot_encoder.fit_transform(X_train[['ProductName', 'Country']])

# Transform the categorical columns in validation and test data using the fitted encoder
X_val_encoded = onehot_encoder.transform(X_val[['ProductName', 'Country']])
X_test_encoded = onehot_encoder.transform(X_test[['ProductName', 'Country']])

# Stack the one-hot encoded features with the numerical features
X_train_encoded = hstack([X_train_encoded, X_train[['Quantity']].values])
X_val_encoded = hstack([X_val_encoded, X_val[['Quantity']].values])
X_test_encoded = hstack([X_test_encoded, X_test[['Quantity']].values])
# We use the hstack to save on memory when evaluating the model

# Linear Regression Model

# Train a Linear Regression model
linear_regression_model = LinearRegression()
linear_regression_model.fit(X_train_encoded, y_train)

"""**Making tests on Validation Data created during Data Splitting**

"""

# Make predictions on the validation data using the Linear Regression model
y_pred_val_linear = linear_regression_model.predict(X_val_encoded)

"""**Performance Evaluation**"""

# Calculate evaluation metrics for the Linear Regression model
mse_linear = mean_squared_error(y_val, y_pred_val_linear)
rmse_linear = np.sqrt(mse_linear)
mae_linear = mean_absolute_error(y_val, y_pred_val_linear)
r2_linear = r2_score(y_val, y_pred_val_linear)

# Print the evaluation metrics
print('Linear Regression - MSE on Validation Data:', mse_linear)
print('Linear Regression - RMSE on Validation Data:', rmse_linear)
print('Linear Regression - MAE on Validation Data:', mae_linear)
print('Linear Regression - R-squared on Validation Data:', r2_linear*100)

# Decision Tree Model

# Create and Train Decision Tree Regressor
decision_tree_model = DecisionTreeRegressor(random_state=42)
decision_tree_model.fit(X_train_encoded, y_train)

"""**Making tests on Validation Data created during Data Splitting**"""

# Make predictions on the validation data
y_pred_val_decision_tree = decision_tree_model.predict(X_val_encoded)

"""

```
# This is formatted as code
```

**Performance Evaluation**"""

# Calculate evaluation metrics for Decision Tree
mse_decision_tree = mean_squared_error(y_val, y_pred_val_decision_tree)
rmse_decision_tree = np.sqrt(mse_decision_tree)
mae_decision_tree = mean_absolute_error(y_val, y_pred_val_decision_tree)
r2_decision_tree = r2_score(y_val, y_pred_val_decision_tree)

# Print the evaluation metrics
print("Decision Tree Metrics:")
print(f"Mean Squared Error (MSE): {mse_decision_tree}")
print(f"Root Mean Squared Error (RMSE): {rmse_decision_tree}")
print(f"Mean Absolute Error (MAE): {mae_decision_tree}")
print(f"R-squared (R2): {r2_decision_tree*100}")